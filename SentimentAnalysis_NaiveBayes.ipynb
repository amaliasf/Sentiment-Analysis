{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Analisis Sentiment - Naive Bayes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZtw61HMZ1GM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3ed2523c-3ed0-49c0-e924-7575b615b3b0"
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "#import file csv\n",
        "file = 'dataset_tweet_2.csv'\n",
        "\n",
        "token_data = open(file)\n",
        "tokens = csv.reader(token_data, delimiter=';')\n",
        "tweets = []\n",
        "label = []\n",
        "for row in tokens:\n",
        "    tweets.append(row[0])\n",
        "    label.append(int(row[1].replace(',','')))\n",
        "\n",
        "df = pd.DataFrame(columns=['tweets','label'])\n",
        "df['tweets'] = tweets\n",
        "df['label'] = label\n",
        "\n",
        "print (df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                               tweets  label\n",
            "0   rt @napqilla: no 1, 3 ambisinya menguasai raky...      1\n",
            "1   rt @pandji: nah gue pikir sentimen petahana ok...      1\n",
            "2   rt @pandji: urutan pertama best moment #debat2...      1\n",
            "3   rt @pandji: ini artikel yg menjelaskan ternyat...      1\n",
            "4   rt @mrtampi: agus makin santai.\\nahok makin sa...      0\n",
            "..                                                ...    ...\n",
            "76  rt @pandji: nah gue pikir sentimen petahana ok...      0\n",
            "77  rt @josua_tm: ibu sylvi adalah contoh bahwa wa...      1\n",
            "78  besok saya ajak kesana saja, saya udah survei ...      1\n",
            "79  benerr bgt.. dan tidak mengajak penonton ikut ...      1\n",
            "80  rt @gandy_koz: pak anis,kl pas libur lebaran i...      1\n",
            "\n",
            "[81 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-EtlqwRaPcJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "83602769-cf5c-40b2-a2a4-cdc76c44e09f"
      },
      "source": [
        "!pip nltk\n",
        "!pip install sastrawi\n",
        "import re,string\n",
        "#import nltk.stem as stemmer\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "clean_tweets = []\n",
        "for tweet in tweets:\n",
        "    def hapus_tanda(tweet): \n",
        "        tanda_baca = set(string.punctuation)\n",
        "        tweet = ''.join(ch for ch in tweet if ch not in tanda_baca)\n",
        "        return tweet\n",
        "    \n",
        "    def hapus_katadouble(s): \n",
        "        pattern = re.compile(r\"(.)\\1{1,}\", re.DOTALL)\n",
        "        return pattern.sub(r\"\\1\\1\", s)\n",
        "\n",
        "    tweet=tweet.lower()\n",
        "    tweet = re.sub(r'\\\\u\\w\\w\\w\\w', '', tweet)\n",
        "    tweet=re.sub(r'http\\S+','',tweet)\n",
        "    #hapus @username\n",
        "    tweet=re.sub('@[^\\s]+','',tweet)\n",
        "    #hapus #tagger \n",
        "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
        "    #hapus tanda baca\n",
        "    tweet=hapus_tanda(tweet)\n",
        "    #hapus angka dan angka yang berada dalam string \n",
        "    tweet=re.sub(r'\\w*\\d\\w*', '',tweet).strip()\n",
        "    #hapus repetisi karakter \n",
        "    tweet=hapus_katadouble(tweet)\n",
        "    #stemming\n",
        "    factory = StemmerFactory()\n",
        "    stemmer = factory.create_stemmer()\n",
        "    tweet = stemmer.stem(tweet)\n",
        "    clean_tweets.append(tweet)\n",
        "\n",
        "df['clean'] = clean_tweets\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR: unknown command \"nltk\"\n",
            "Collecting sastrawi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4b/bab676953da3103003730b8fcdfadbdd20f333d4add10af949dd5c51e6ed/Sastrawi-1.0.1-py2.py3-none-any.whl (209kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 8.1MB/s \n",
            "\u001b[?25hInstalling collected packages: sastrawi\n",
            "Successfully installed sastrawi-1.0.1\n",
            "                                              tweets  ...                                              clean\n",
            "0  rt @napqilla: no 1, 3 ambisinya menguasai raky...  ...  rt no ambisi kuasa rakyat ambisi layan rakyat ...\n",
            "1  rt @pandji: nah gue pikir sentimen petahana ok...  ...  rt nah gue pikir sentimen tahana oke di malam ...\n",
            "2  rt @pandji: urutan pertama best moment #debat2...  ...  rt urut pertama best moment pak basuki misahin...\n",
            "3  rt @pandji: ini artikel yg menjelaskan ternyat...  ...  rt ini artikel yg jelas nyata di yg dapet resp...\n",
            "4  rt @mrtampi: agus makin santai.\\nahok makin sa...  ...  rt agus makin santainahok makin santunnanies m...\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utHzrazUbI0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "18875b60-f962-432f-ca7a-c55cc21071cc"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "vectorizer = TfidfVectorizer (max_features=2500)\n",
        "model_g = GaussianNB()\n",
        "\n",
        "v_data = vectorizer.fit_transform(df['clean']).toarray()\n",
        "\n",
        "print (v_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b0p-nocbPXH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "659a8f6e-55d8-4fb1-9c4b-1b5fad5c1497"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(v_data, df['label'], test_size=0.2, random_state=0)\n",
        "model_g.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp4zamwzbSmg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "349a1772-c12e-43eb-deec-4c7ff87d905c"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "y_preds = model_g.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,y_preds))\n",
        "print(classification_report(y_test,y_preds))\n",
        "print('nilai akurasinya adalah ',accuracy_score(y_test, y_preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8 4]\n",
            " [1 4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.67      0.76        12\n",
            "           1       0.50      0.80      0.62         5\n",
            "\n",
            "    accuracy                           0.71        17\n",
            "   macro avg       0.69      0.73      0.69        17\n",
            "weighted avg       0.77      0.71      0.72        17\n",
            "\n",
            "nilai akurasinya adalah  0.7058823529411765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6xNdrtFbV6N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e64d027-81d7-4f37-c7db-b2d31910a424"
      },
      "source": [
        "tweet = ''\n",
        "v_data = vectorizer.transform([tweet]).toarray()\n",
        "y_preds = model_g.predict(v_data)\n",
        "\n",
        "if y_preds == 1:\n",
        "    print('Positif')\n",
        "else:\n",
        "    print('Negatif')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positif\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}