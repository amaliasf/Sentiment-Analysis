{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis - SQL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DOe91WbSXiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "528b4e3b-592e-4012-ee24-29d6b3b48088"
      },
      "source": [
        "#import library and all the required key\n",
        "!pip install sastrawi\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "import tweepy\n",
        "#import csv, re\n",
        "import re,string\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "import collections\n",
        "\n",
        "class data_analisis:\n",
        "  def __init__ (self):\n",
        "    pass\n",
        "  \n",
        "  def open_file(self, file):\n",
        "      con = sqlite3.connect(file)\n",
        "      df = pd.read_sql_query(\"SELECT * from data_tweet\", con)\n",
        "      con.close()\n",
        "      print (df)\n",
        "      return df\n",
        "    \n",
        "  def praproses(self, data):\n",
        "      clean_tweets = []\n",
        "      tweets = []\n",
        "      # data['Tweets'] = tweets\n",
        "      # tweet = data[\"Tweets\"]\n",
        "      for tweet in data['Tweets']:\n",
        "        def hapus_tanda(tweet): \n",
        "            tanda_baca = set(string.punctuation)\n",
        "            tweet = ''.join(ch for ch in tweet if ch not in tanda_baca)\n",
        "            return tweet\n",
        "            \n",
        "        def hapus_katadouble(s): \n",
        "            pattern = re.compile(r\"(.)\\1{1,}\", re.DOTALL)\n",
        "            return pattern.sub(r\"\\1\\1\", s)\n",
        "        \n",
        "        #mengecilkan huruf\n",
        "        tweet=tweet.lower()\n",
        "        #hapus link\n",
        "        tweet = re.sub(r'\\\\u\\w\\w\\w\\w', '', tweet)\n",
        "        tweet=re.sub(r'http\\S+','',tweet)\n",
        "        #hapus @username\n",
        "        tweet=re.sub('@[^\\s]+','',tweet)\n",
        "        #hapus #tagger \n",
        "        tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
        "        #hapus tanda baca\n",
        "        tweet=hapus_tanda(tweet)\n",
        "        #hapus angka yang berada dalam string \n",
        "        tweet=re.sub(r'\\w*\\d\\w*', '',tweet).strip()\n",
        "        #hapus repetisi karakter \n",
        "        tweet=hapus_katadouble(tweet)\n",
        "        #stemming\n",
        "        factory = StemmerFactory()\n",
        "        stemmer = factory.create_stemmer()\n",
        "        tweet = stemmer.stem(tweet)\n",
        "        clean_tweets.append(tweet)\n",
        "        \n",
        "      # data['clean'] = clean_tweets\n",
        "      return(clean_tweets)\n",
        "\n",
        "  def hitung_kata(self, data):\n",
        "\n",
        "    words_in_tweet = [tweet.lower().split() for tweet in data]\n",
        "    \n",
        "    # words_in_tweet[:2]\n",
        "    data = data[0].lower().split()\n",
        "    print (data)\n",
        "    # List of all words across tweets\n",
        "    all_words_no_urls = list(itertools.chain(*words_in_tweet))\n",
        "\n",
        "    # Create counter\n",
        "    counts_no_urls = collections.Counter(data)\n",
        "    counts_no_urls.most_common(15)\n",
        "\n",
        "    clean_tweets = pd.DataFrame(counts_no_urls.most_common(15),  columns=['words', 'count'])\n",
        "    print (clean_tweets)\n",
        "\n",
        "\n",
        "  def analisis_sentiment(self, clean_data):\n",
        "    pos_list= open(\"./kata_positif.txt\",\"r\")\n",
        "    pos_kata = pos_list.readlines()\n",
        "    neg_list= open(\"./kata_negatif.txt\",\"r\")\n",
        "    neg_kata =  neg_list.readlines()\n",
        "\n",
        "    Sentiment = []\n",
        "    for item in clean_data:\n",
        "      count_p = 0\n",
        "      count_n = 0\n",
        "      for kata_pos in pos_kata:\n",
        "          if kata_pos.strip() in item:\n",
        "            count_p +=1\n",
        "      for kata_neg in neg_kata:\n",
        "          if kata_neg.strip() in item:\n",
        "            count_n +=1\n",
        "\n",
        "      Sentiment.append(count_p - count_n)\n",
        "    \n",
        "    return (Sentiment)\n",
        "\n",
        "  def visualisasi(self, Sentiment):\n",
        "    #Menghitung mean, median, dan standart deviasi\n",
        "    print (\"Nilai rata-rata: \"+str(np.mean(Sentiment)))\n",
        "    print (\"Median: \"+str(np.median(Sentiment)))\n",
        "    print (\"Standart Deviasi: \"+str(np.std(Sentiment)))\n",
        "\n",
        "    labels, counts = np.unique(Sentiment, return_counts=True)\n",
        "    plt.bar(labels, counts, align='center')\n",
        "    plt.gca().set_xticks(labels)\n",
        "    plt.show()\n",
        "\n",
        "file = \"tugasakhir.db\"\n",
        "app = data_analisis()\n",
        "#open the database file\n",
        "data = app.open_file(file)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sastrawi in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "                      ID  ...                    Lokasi\n",
            "0    1319426925522161664  ...                          \n",
            "1    1319424690234904577  ...                 Indonesia\n",
            "2    1319422818178584578  ...                          \n",
            "3    1319421172656730112  ...   Tasikmalaya, Jawa Barat\n",
            "4    1319419774221258753  ...                 Indonesia\n",
            "..                   ...  ...                       ...\n",
            "747  1318733744459579392  ...                          \n",
            "748  1318730579324514305  ...                          \n",
            "749  1318719833559629825  ...                 Indonesia\n",
            "750  1318719672422858752  ...                     bogor\n",
            "751  1318714322860662784  ...             di bumi ALLAH\n",
            "\n",
            "[752 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMfnPkF-AJeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7744bffa-5f6c-44f2-8e34-a30096799238"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ID', 'Tweets', 'Waktu', 'Akun', 'Lokasi'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_22LLMVAbTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "035f62ac-18a6-4b2d-e190-8b6fc091ea63"
      },
      "source": [
        "data.groupby('Lokasi')['Lokasi'].count().max"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Series.max of Lokasi\n",
              "                            330\n",
              " Indonesia                    2\n",
              " Tasikmalaya, Jawa Barat      1\n",
              "+62                           3\n",
              ".......                       1\n",
              "                           ... \n",
              "ðŸ‡®ðŸ‡© Indonesia                  1\n",
              "ðŸ‡®ðŸ‡©#NetizenProNKRIðŸ‡®ðŸ‡©           1\n",
              "ðŸŒ                             1\n",
              "ðŸ•‹Atjeh ðŸ•Œâ—à¹‹â€¢                   1\n",
              "ðŸ¤¡                             2\n",
              "Name: Lokasi, Length: 273, dtype: int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}